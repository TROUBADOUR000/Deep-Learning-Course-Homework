{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:07.846521Z",
     "start_time": "2024-03-12T13:51:02.842194Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "def mnist_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:07.893865Z",
     "start_time": "2024-03-12T13:51:07.847642Z"
    }
   },
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, input_dim=784, output_dim=10, hidden_dim=2048):\n",
    "        ####################\n",
    "        '''声明模型对应的参数'''\n",
    "        ####################\n",
    "        super(myModel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.LogSoftmax(1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ####################\n",
    "        '''实现模型函数体，返回未归一化的logits'''\n",
    "        ####################\n",
    "        return self.net(x)\n",
    "        \n",
    "model = myModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00002, weight_decay=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:07.909934Z",
     "start_time": "2024-03-12T13:51:07.895150Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels):\n",
    "    label = torch.argmax(labels, dim=1)\n",
    "    log_probs_for_labels = logits[range(logits.shape[0]), label]\n",
    "    loss = -torch.mean(log_probs_for_labels)\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    label = torch.argmax(labels, dim=1)\n",
    "    correct = torch.sum(predictions == label).item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    model.train()\n",
    "\n",
    "    logits = model(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss = compute_loss(logits, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    # loss and accuracy is scalar tensor\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def test(model, x, y):\n",
    "    model.eval()\n",
    "    logits = model(x)\n",
    "    loss = compute_loss(logits, y)\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实际训练"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data = mnist_dataset()\n",
    "train_label = np.zeros(shape=[len(train_data), 10])\n",
    "test_label = np.zeros(shape=[len(test_data), 10])\n",
    "for i, (_, label) in enumerate(train_data):\n",
    "    train_label[i, label] = 1.\n",
    "for i, (_, label) in enumerate(test_data):\n",
    "    test_label[i, label] = 1.\n",
    "train_data = torch.stack([image for image, _ in train_data])\n",
    "test_data = torch.stack([image for image, _ in test_data])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:24.884397Z",
     "start_time": "2024-03-12T13:51:07.913935Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(60000, 784)\n",
    "test_data = test_data.reshape(10000, 784)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:24.900104Z",
     "start_time": "2024-03-12T13:51:24.887155Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_label = torch.tensor(train_label)\n",
    "test_label = torch.tensor(test_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:51:24.914777Z",
     "start_time": "2024-03-12T13:51:24.902312Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 2.3108542 ; accuracy 0.04985\n",
      "epoch 1 : loss 2.3047106 ; accuracy 0.06091666666666667\n",
      "epoch 2 : loss 2.298585 ; accuracy 0.07336666666666666\n",
      "epoch 3 : loss 2.292476 ; accuracy 0.08945\n",
      "epoch 4 : loss 2.2863839 ; accuracy 0.1079\n",
      "epoch 5 : loss 2.2803078 ; accuracy 0.12588333333333335\n",
      "epoch 6 : loss 2.2742474 ; accuracy 0.14758333333333334\n",
      "epoch 7 : loss 2.268202 ; accuracy 0.17235\n",
      "epoch 8 : loss 2.2621713 ; accuracy 0.19915\n",
      "epoch 9 : loss 2.256154 ; accuracy 0.22688333333333333\n",
      "epoch 10 : loss 2.2501507 ; accuracy 0.2553166666666667\n",
      "epoch 11 : loss 2.24416 ; accuracy 0.28386666666666666\n",
      "epoch 12 : loss 2.2381806 ; accuracy 0.31315\n",
      "epoch 13 : loss 2.2322125 ; accuracy 0.3435\n",
      "epoch 14 : loss 2.2262542 ; accuracy 0.37201666666666666\n",
      "epoch 15 : loss 2.2203045 ; accuracy 0.3993333333333333\n",
      "epoch 16 : loss 2.2143629 ; accuracy 0.4252666666666667\n",
      "epoch 17 : loss 2.208428 ; accuracy 0.44953333333333334\n",
      "epoch 18 : loss 2.2024987 ; accuracy 0.4741666666666667\n",
      "epoch 19 : loss 2.196574 ; accuracy 0.4977666666666667\n",
      "epoch 20 : loss 2.190653 ; accuracy 0.5198333333333334\n",
      "epoch 21 : loss 2.1847346 ; accuracy 0.5395333333333333\n",
      "epoch 22 : loss 2.1788175 ; accuracy 0.55695\n",
      "epoch 23 : loss 2.172901 ; accuracy 0.57355\n",
      "epoch 24 : loss 2.1669838 ; accuracy 0.5882\n",
      "epoch 25 : loss 2.1610646 ; accuracy 0.6025333333333334\n",
      "epoch 26 : loss 2.155142 ; accuracy 0.61515\n",
      "epoch 27 : loss 2.1492162 ; accuracy 0.6257666666666667\n",
      "epoch 28 : loss 2.1432853 ; accuracy 0.6358666666666667\n",
      "epoch 29 : loss 2.1373482 ; accuracy 0.64435\n",
      "epoch 30 : loss 2.1314042 ; accuracy 0.6520666666666667\n",
      "epoch 31 : loss 2.1254523 ; accuracy 0.65895\n",
      "epoch 32 : loss 2.1194916 ; accuracy 0.6657166666666666\n",
      "epoch 33 : loss 2.113521 ; accuracy 0.6715\n",
      "epoch 34 : loss 2.10754 ; accuracy 0.6771166666666667\n",
      "epoch 35 : loss 2.1015472 ; accuracy 0.6825666666666667\n",
      "epoch 36 : loss 2.0955422 ; accuracy 0.68715\n",
      "epoch 37 : loss 2.089524 ; accuracy 0.6917666666666666\n",
      "epoch 38 : loss 2.0834916 ; accuracy 0.6963\n",
      "epoch 39 : loss 2.0774443 ; accuracy 0.7002166666666667\n",
      "epoch 40 : loss 2.0713816 ; accuracy 0.7044666666666667\n",
      "epoch 41 : loss 2.0653024 ; accuracy 0.7085666666666667\n",
      "epoch 42 : loss 2.059207 ; accuracy 0.7123666666666667\n",
      "epoch 43 : loss 2.0530937 ; accuracy 0.7155\n",
      "epoch 44 : loss 2.0469627 ; accuracy 0.7189666666666666\n",
      "epoch 45 : loss 2.0408127 ; accuracy 0.7220166666666666\n",
      "epoch 46 : loss 2.034643 ; accuracy 0.7249\n",
      "epoch 47 : loss 2.0284534 ; accuracy 0.72805\n",
      "epoch 48 : loss 2.0222437 ; accuracy 0.73105\n",
      "epoch 49 : loss 2.016013 ; accuracy 0.7335\n",
      "test loss 2.0055962 ; accuracy 0.7402\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    loss, accuracy = train_one_step(model, optimizer, train_data, train_label)\n",
    "    print('epoch', epoch, ': loss', loss.detach().numpy(), '; accuracy', accuracy)\n",
    "loss, accuracy = test(model, test_data, test_label)\n",
    "\n",
    "print('test loss', loss.detach().numpy(), '; accuracy', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T13:56:47.338181Z",
     "start_time": "2024-03-12T13:51:24.916778Z"
    }
   },
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
